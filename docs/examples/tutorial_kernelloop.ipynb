{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Parcels Kernel loop\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial explains how Parcels executes multiple Kernels, and what happens under the hood when you combine Kernels. \n",
    "\n",
    "This is probably not very relevant when you only use the built-in Advection kernels, but can be important when you are writing and combining your own Kernels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "When you run a Parcels simulation (i.e. a call to `pset.execute()`), the Kernel loop is the main part of the code that is executed. This part of the code loops through all particles and executes the Kernels that are defined for each particle.\n",
    "\n",
    "In order to make sure that the displacements of a particle in the different Kernels can be summed, all Kernels add to a _change_ in position (`particles.dlon`, `particles.dlat`, and `particles.ddepth`). This is important, because there are situations where movement kernels would otherwise not commute. Take the example of advecting particles by currents _and_ winds. If the particle would first be moved by the currents and then by the winds, the result could be different from first moving by the winds and then by the currents. Instead, by adding the changes in position, the ordering of the Kernels has no consequence on the particle displacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a structured overview of the Kernel loop is implemented. Note that this is for longitude only, but the same process is applied for latitude and depth.\n",
    "\n",
    "1. Initialise an extra Variable `particles.lon=0` and `particles.time_nextloop = particles.time`\n",
    "\n",
    "2. Within the Kernel loop, for each particle:<br>\n",
    "\n",
    "    1. Update `particles.lon += particles.dlon`<br>\n",
    "\n",
    "    2. Set variable `particles.dlon = 0`<br>\n",
    "\n",
    "    3. Update `particles.time = particles.time_nextloop`\n",
    "\n",
    "    4. For each Kernel in the list of Kernels:\n",
    "        \n",
    "        1. Execute the Kernel\n",
    "        \n",
    "        2. Update `particles.dlon` by adding the change in longitude, if needed<br>\n",
    "\n",
    "    5. Update `particles.time_nextloop += particles.dt`<br>\n",
    "\n",
    "    6. If `outputdt` is a multiple of `particle.time`, write `particle.lon` and `particle.time` to zarr output file<br>\n",
    "\n",
    "Besides having commutable Kernels, the main advantage of this implementation is that, when using Field Sampling with e.g. `particle.temp = fieldset.Temp[particle.time, particle.depth, particle.lat, particle.lon]`, the particle location stays the same throughout the entire Kernel loop. Additionally, this implementation ensures that the particle location is the same as the location of the sampled field in the output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple example of some particles at the surface of the ocean. We create an idealised zonal wind flow that will \"push\" a particle that is already affected by the surface currents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import parcels\n",
    "\n",
    "# Load the GlobCurrent data in the Agulhas region from the example_data\n",
    "example_dataset_folder = parcels.download_example_dataset(\"GlobCurrent_example_data\")\n",
    "filenames = {\n",
    "    \"U\": f\"{example_dataset_folder}/20*.nc\",\n",
    "    \"V\": f\"{example_dataset_folder}/20*.nc\",\n",
    "}\n",
    "variables = {\n",
    "    \"U\": \"eastward_eulerian_current_velocity\",\n",
    "    \"V\": \"northward_eulerian_current_velocity\",\n",
    "}\n",
    "dimensions = {\"lat\": \"lat\", \"lon\": \"lon\", \"time\": \"time\"}\n",
    "fieldset = parcels.FieldSet.from_netcdf(\n",
    "    filenames, variables, dimensions, allow_time_extrapolation=True\n",
    ")\n",
    "# uppermost layer in the hydrodynamic data\n",
    "fieldset.mindepth = fieldset.U.depth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an idealised wind field and add it to the fieldset\n",
    "xdim, ydim = (len(fieldset.U.lon), len(fieldset.U.lat))\n",
    "UWind = parcels.Field(\n",
    "    \"UWind\",\n",
    "    np.ones((ydim, xdim), dtype=np.float32) * np.sin(fieldset.U.lat)[:, None],\n",
    "    lon=fieldset.U.lon,\n",
    "    lat=fieldset.U.lat,\n",
    "    mesh=\"spherical\",\n",
    ")\n",
    "VWind = parcels.Field(\n",
    "    \"VWind\",\n",
    "    np.zeros((ydim, xdim), dtype=np.float32),\n",
    "    grid=UWind.grid,\n",
    ")\n",
    "UWind.units = parcels.tools.converters.GeographicPolar()\n",
    "VWind.units = parcels.tools.converters.Geographic()\n",
    "\n",
    "fieldset_wind = parcels.FieldSet(UWind, VWind)\n",
    "\n",
    "fieldset.add_field(fieldset_wind.U, name=\"UWind\")\n",
    "fieldset.add_field(fieldset_wind.V, name=\"VWind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a wind kernel that uses a forward Euler method to apply the wind forcing. Note that we update the `particle_dlon` and `particle_dlat` variables, rather than `particle.lon` and `particle.lat` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_kernel(particle, fieldset, time):\n",
    "    particle_dlon += (\n",
    "        fieldset.UWind[time, particle.depth, particle.lat, particle.lon] * particle.dt\n",
    "    )\n",
    "    particle_dlat += (\n",
    "        fieldset.VWind[time, particle.depth, particle.lat, particle.lon] * particle.dt\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a simulation where we apply first kernels as `[AdvectionRK4, wind_kernel]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = 26.0 * np.ones(10)\n",
    "lats = np.linspace(-37.5, -34.5, 10)\n",
    "\n",
    "pset = parcels.ParticleSet(fieldset, pclass=parcels.Particle, lon=lons, lat=lats)\n",
    "output_file = pset.ParticleFile(\n",
    "    name=\"advection_then_wind.zarr\", outputdt=timedelta(hours=6)\n",
    ")\n",
    "pset.execute(\n",
    "    [parcels.AdvectionRK4, wind_kernel],\n",
    "    runtime=timedelta(days=5),\n",
    "    dt=timedelta(hours=1),\n",
    "    output_file=output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also run a simulation where we apply the kernels in the reverse order as `[wind_kernel, AdvectionRK4]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset_reverse = parcels.ParticleSet(\n",
    "    fieldset, pclass=parcels.Particle, lon=lons, lat=lats\n",
    ")\n",
    "output_file_reverse = pset_reverse.ParticleFile(\n",
    "    name=\"wind_then_advection.zarr\", outputdt=timedelta(hours=6)\n",
    ")\n",
    "pset_reverse.execute(\n",
    "    [wind_kernel, parcels.AdvectionRK4],\n",
    "    runtime=timedelta(days=5),\n",
    "    dt=timedelta(hours=1),\n",
    "    output_file=output_file_reverse,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot the trajectories to show that they are identical in the two simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resulting particle trajectories overlapped for both cases\n",
    "advection_then_wind = xr.open_zarr(\"advection_then_wind.zarr\")\n",
    "wind_then_advection = xr.open_zarr(\"wind_then_advection.zarr\")\n",
    "plt.plot(wind_then_advection.lon.T, wind_then_advection.lat.T, \"-\")\n",
    "plt.plot(advection_then_wind.lon.T, advection_then_wind.lat.T, \"--\", c=\"k\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few important considerations to take into account when writing Kernels\n",
    "\n",
    "### 1. Avoid updating particle locations directly in Kernels\n",
    "It is better not to update `particle.lon` directly in a Kernel, as it can interfere with the loop above. Assigning a value to `particle.lon` in a Kernel will throw a warning. \n",
    "\n",
    "Instead, update the local variable `particle.dlon`.\n",
    "\n",
    "### 2. Be careful with updating particle variables that do not depend on Fields.\n",
    "While assigning the interpolated value of a `Field` to a Particle goes well in the loop above, this is not necessarily so for assigning other attributes. For example, a line like `particle.age += particle.dt` is executed directly so may result in the age being `dt` at `time = 0` in the output file. \n",
    "\n",
    "A workaround is to either initialise the age to `-dt`, or to increase the `age` only when `particle.time > 0` (using an `np.where` statement).\n",
    "\n",
    "\n",
    "### 3. The last time is not written to file\n",
    "Because the location at the start of the loop is written at the end of the Kernel loop, the last `particle.time` of the particle is not written to file. This is similar behaviour to e.g. `np.arange(start, stop)`, which also doesn't include the `stop` value itself. \n",
    "\n",
    "If you do want to write the last time to file, you can increase the `runtime` or `endtime` by `dt` (although this may cause a TimeExtrapolationError if your run was to the end of the available hydrodynamic data), or you can call `pfile.write_latest_locations(pset, time=pset[0].time_nextloop)`. Note that in the latter case, the particle locations (longitude, latitude and depth) will be updated, but other variables will _not_ be updated as the Kernels are not run again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Status Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to capture errors in the Kernel loop, Parcels uses a Status Code system. There are several Status Codes, listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parcels import StatusCode\n",
    "\n",
    "for statuscode, val in StatusCode.__dict__.items():\n",
    "    if statuscode.startswith(\"__\"):\n",
    "        continue\n",
    "    print(f\"{statuscode} = {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once an error is thrown (for example, a Field Interpolation error), then the `particle.state` is updated to the corresponding status code. This gives you the flexibility to write a Kernel that checks for a status code and does something with it. \n",
    "\n",
    "For example, you can write a Kernel that checks for `particle.state == StatusCode.ErrorOutOfBounds` and deletes the particle, and then append this to the Kernel list in `pset.execute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckOutOfBounds(particle, fieldset, time):\n",
    "    if particle.state == StatusCode.ErrorOutOfBounds:\n",
    "        particle.delete()\n",
    "\n",
    "\n",
    "def CheckError(particle, fieldset, time):\n",
    "    if particle.state >= 50:  # This captures all Errors\n",
    "        particle.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But of course, you can also write code for more sophisticated behaviour than just deleting the particle. It's up to you! Note that if you don't delete the particle, you will have to update the `particle.state = StatusCode.Success` yourself. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Move1DegreeWest(particle, fieldset, time):\n",
    "    if particle.state == StatusCode.ErrorOutOfBounds:\n",
    "        particle_dlon -= 1.0\n",
    "        particle.state = StatusCode.Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if you want to make sure that particles don't escape through the water surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KeepInOcean(particle, fieldset, time):\n",
    "    if particle.state == StatusCode.ErrorThroughSurface:\n",
    "        particle_ddepth = 0.0\n",
    "        particle.state = StatusCode.Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel functions such as the ones above can then be added to the list of kernels in `pset.execute()`. \n",
    "\n",
    "Note that these Kernels that control what to do with `particle.state` should typically be added at the _end_ of the Kernel list, because otherwise later Kernels may overwrite the `particle.state` or the `particle_dlon` variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parcels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
