{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parcels trajectories with geospatial data types and software"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**  \n",
    "This tutorial goes over converting parcels particle trajectory data into various common geospatial data formats including:\n",
    "\n",
    "* Shapefile\n",
    "* Geopackage\n",
    "* GeoJSON\n",
    "* KML\n",
    "\n",
    "This allows for easy integration of Parcels output with any geospatial workflows you have, or geospatial tools you would like for further visualization and analysis. Geospatial software covered in this tutorial include:\n",
    "\n",
    "* GIS Software ([QGIS](https://qgis.org/en/site/) and [ArcGIS](https://www.arcgis.com/index.html))\n",
    "* [Kepler.gl](https://kepler.gl/)\n",
    "* [Google Earth](https://www.google.com/earth/versions/)\n",
    "\n",
    "This code has been written to make it as \"production ready\" and \"copy pastable\" as possible to help with your workflows. This tutorial also highlights the limitations of some geospatial datasets and tools when it comes to working with large datasets (which parcels tends to output).\n",
    "\n",
    "**Tutorial requirements:**  \n",
    "Most of this tutorial requires your simulation is run using longitude and latitude in degrees (as opposed to being in metres).\n",
    "\n",
    "This tutorial requires the following packages:\n",
    "- [geopandas](https://geopandas.org/) to create the geospatial datasets (`conda install -c conda-forge geopandas`)\n",
    "- [lxml](https://lxml.de/) to create KML files for Google Earth (`conda install lxml`)\n",
    "\n",
    "This tutorial saves all generated data output in a folder `tutorial_geospatial_output` to avoid clogging the working directory. If you're re-running this notebook, be sure to delete this folder so that the notebook doesn't encounter writing issues."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIS data types\n",
    "\n",
    "There are mainly two types of geospatial data:\n",
    "* Raster data\n",
    "* Vector data\n",
    "\n",
    "See [this article](https://gisgeography.com/spatial-data-types-vector-raster/) for an explainer of raster vs vector data types.\n",
    "\n",
    "Various geospatial dataset types exist for raster and vector data. Here we go over a few of them, discussing their advantages and disadvantages.\n",
    "\n",
    "\n",
    "### NetCDF (.nc)\n",
    "A raster data format for storing and sharing large, multi-dimensional arrays of scientific data, often used for gridded climate and oceanographic datasets. May need some processing before visualizing depending on setup of the NetCDF.\n",
    "\n",
    "### Shapefile (.shp, ...)\n",
    "The longest standing geospatial vector data format used for storing location data and associated attribute information. Shapefile is a multifile format, where the dataset is split into files with different extensions handling vector (.shp), indexing (.shx), attribute (.dbf), encoding (.cpg), and projection (.prj) information. The shapefile is a [geospatial data format with many limitations](http://switchfromshapefile.org/) compared to other geospatial data formats.\n",
    "\n",
    "- Pros:\n",
    "    - The oldest data format. Has wide adoption across various GIS tools.\n",
    "- Cons:\n",
    "    - Limits on:\n",
    "        - variable name lengths (10 characters)\n",
    "        - variable types\n",
    "        - file size (2Gb max)\n",
    "    - No NULL value\n",
    "    - No time data type.\n",
    "    - Can only contain a single layer (i.e. you can't mix geospatial data types in a single file).\n",
    "\n",
    "\n",
    "### GeoJSON (.geojson)\n",
    "A lightweight, human-readable, vector data format for encoding geospatial data structures, such as points, lines, and polygons, using JavaScript Object Notation (JSON). Commonly used in web applications.\n",
    "\n",
    "\n",
    "### KML (.kml) and KMZ (.kmz)\n",
    "XML-based vector formats for expressing geographic annotations and visualizations on 2D maps and 3D Earth browsers, such as Google Earth. KMZ is a compressed version of KML.\n",
    "\n",
    "### GeoPackage (.gpkg)\n",
    "A modern, open, standards-based, platform-independent format for storing geospatial data. Operates using an SQLite database, and is capable of storing multiple layers in a single dataset. Can contain raster and vector layers.\n",
    "\n",
    "\n",
    "### Geodatabase (.gdb)\n",
    "A proprietary Esri format for storing, querying, and managing geospatial data, including vector, raster, and tabular data. This tutorial does not cover Geodatabases.\n",
    "\n",
    "\n",
    "---\n",
    "For geospatial vector datasets, layers can only contain one feature type. Each feature in a geospatial dataset can have associated data (timestamps, text, numeric values) depending on what the data represents. There are 3 types of features in geospatial datasets:\n",
    "\n",
    "- **Point:** Describes individual coordinates on earth.\n",
    "- **Linestring:** Describes individual lines on earth (is composed of a sequence of coordinates, which are joined in an open loop).\n",
    "- **Polygon:** Describes individual polygons on earth (is composed of a sequence of coordinates, which are joined in a closed loop).\n",
    "\n",
    "Here there are two logical choices for representing particle trajectory data, using *points* or *linestrings*. Using points, all the data (including timestamps) is preserved, but the path of the particle may not be inherently evident on the software being used to load the point data. The timestamp information is tied as data for that point, and may not be visualized by the software. Representing trajectories as linestrings makes it easy to visualize trajectories in GIS software, but extra data regarding the individual point observations (i.e. all data except (lon, lat) location data) is lost in this format.\n",
    "\n",
    "These limitations mainly apply to Shapefile, GeoJSON, GeoPackage, and Geodatabase formats when used in GIS applications. As explored later, Google Earth (KML) has syntax specifically for visualizing trajectories, and Kepler accepts modified GeoJSON to represent trajectory data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating geospatial datasets from parcels output\n",
    "First, we run import all the packages needed for this tutorial, run an example parcels simulation and save the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import requests\n",
    "import xarray as xr\n",
    "from lxml import etree\n",
    "from shapely.geometry import LineString, Point\n",
    "\n",
    "import parcels\n",
    "\n",
    "DATA_OUTPUT_FOLDER = Path(\"tutorial_geospatial_output\")\n",
    "DATA_OUTPUT_FOLDER.mkdir(exist_ok=True)\n",
    "DATA_OUTPUT_NAME = \"agulhas_trajectories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example parcels simulation\n",
    "data_folder = parcels.download_example_dataset(\"GlobCurrent_example_data\")\n",
    "filenames = filename = str(data_folder / \"20*.nc\")\n",
    "variables = {\n",
    "    \"U\": \"eastward_eulerian_current_velocity\",\n",
    "    \"V\": \"northward_eulerian_current_velocity\",\n",
    "}\n",
    "dimensions = {\n",
    "    \"lat\": \"lat\",\n",
    "    \"lon\": \"lon\",\n",
    "    \"time\": \"time\",\n",
    "}\n",
    "\n",
    "fieldset = parcels.FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "# Mesh of particles\n",
    "lons, lats = np.meshgrid(range(15, 35, 2), range(-40, -30, 2))\n",
    "pset = parcels.ParticleSet(\n",
    "    fieldset=fieldset, pclass=parcels.Particle, lon=lons, lat=lats\n",
    ")\n",
    "dt = timedelta(hours=24)\n",
    "output_file = pset.ParticleFile(\n",
    "    name=DATA_OUTPUT_FOLDER / f\"{DATA_OUTPUT_NAME}.zarr\", outputdt=dt\n",
    ")\n",
    "\n",
    "\n",
    "def DeleteParticle(particle, fieldset, time):\n",
    "    if particle.state > 4:\n",
    "        particle.delete()\n",
    "\n",
    "\n",
    "pset.execute(\n",
    "    [parcels.AdvectionRK4, DeleteParticle],\n",
    "    runtime=timedelta(days=120),\n",
    "    dt=dt,\n",
    "    output_file=output_file,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a zarr dataset stored in the `tutorial_geospatial_example_trajectories.zarr` folder. We can open this using xarray into an `xarray.Dataset` object and process it into different geospatial datasets.\n",
    "\n",
    "First up is the easiest, **NetCDF**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_parcels = xr.open_zarr(DATA_OUTPUT_FOLDER / f\"{DATA_OUTPUT_NAME}.zarr\")\n",
    "\n",
    "ds_parcels.to_netcdf(DATA_OUTPUT_FOLDER / f\"{DATA_OUTPUT_NAME}.nc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the NetCDF format is very similar to zarr, there is no need for extra processing. The other datatypes will require some more work to convert the raster data to a vector format.\n",
    "\n",
    "For this, `geopandas` is used which extends the `pandas` DataFrame object with various geospatial capabilities to create a `GeoDataFrame` object ([learn more about the geopandas project](https://geopandas.org/)). Geopandas, like pandas, operates with data in-memory, which will require the data to be loaded into RAM (as opposed to being lazy loaded like with NetCDF and zarr datasets). To avoid loading in huge datasets, we code in some safeguards. If your dataset is too large, it is recommended you subset your `xr.Dataset` to reduce its size before proceeding with converting to the geospatial datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcels_to_geopandas(ds, suppress_warnings=False):\n",
    "    \"\"\"\n",
    "    Converts your parcels data to a geopandas dataframe containing a point for\n",
    "    every observation in the dataframe. Custom particle variables come along\n",
    "    for the ride during the transformation. Any undefined observations are removed\n",
    "    (correspond to the particle being deleted, or not having entered the simulation).\n",
    "\n",
    "    Assumes your parcel output is in lat and lon.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xr.Dataset\n",
    "        Dataset object in the format of parcels output.\n",
    "\n",
    "    suppress_warnings : bool\n",
    "        Whether to ignore RAM warning.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        GeoDataFrame with point data for each particle observation in the dataset.\n",
    "    \"\"\"\n",
    "    RAM_LIMIT_BYTES = 4 * 1000 * 1000  # 4 GB RAM limit\n",
    "\n",
    "    if ds.nbytes > RAM_LIMIT_BYTES and not suppress_warnings:\n",
    "        raise MemoryError(\n",
    "            f\"Dataset is {ds.nbytes:_} bytes, but RAM_LIMIT_BYTES set max to be {RAM_LIMIT_BYTES:_}.\"\n",
    "        )\n",
    "\n",
    "    df = (\n",
    "        ds.to_dataframe().reset_index()  # Convert `obs` and `trajectory` indices to be columns instead\n",
    "    )\n",
    "\n",
    "    gdf = (\n",
    "        gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]))\n",
    "        .drop(\n",
    "            [\"lon\", \"lat\"], axis=1\n",
    "        )  # No need for lon and lat cols. Included in geometry attribute\n",
    "        .set_crs(\n",
    "            \"EPSG:4326\"\n",
    "        )  # Set coordinate reference system to EPSG:4326 (aka. WGS84; the lat lon reference system)\n",
    "    )\n",
    "\n",
    "    # Remove observations with no time from gdf (indicate particle has been removed, or isn't in simulation)\n",
    "    invalid_observations = gdf[\"time\"].isna()\n",
    "    return gdf[~invalid_observations]\n",
    "\n",
    "\n",
    "gdf_parcels = parcels_to_geopandas(ds_parcels)\n",
    "gdf_parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output GeoDataFrame to geospatial file format (format inferred from extension)\n",
    "gdf_parcels.to_file(DATA_OUTPUT_FOLDER / f\"{DATA_OUTPUT_NAME}.geojson\")\n",
    "gdf_parcels.to_file(DATA_OUTPUT_FOLDER / f\"{DATA_OUTPUT_NAME}.gpkg\")\n",
    "\n",
    "# Shapefile can't handle datetime objects. Converting to seconds since 01/01/1970.\n",
    "gdf_shapefile = gdf_parcels.copy()\n",
    "gdf_shapefile[\"time\"] = (\n",
    "    gdf_shapefile[\"time\"] - datetime.datetime(1970, 1, 1)\n",
    ").dt.total_seconds()\n",
    "gdf_shapefile.to_file(\n",
    "    DATA_OUTPUT_FOLDER / f\"{DATA_OUTPUT_NAME}_shapefile\"\n",
    ")  # Saves in dedicated subfolder all shapefile component files\n",
    "\n",
    "# Converting to KML is covered in the Google Earth software section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our observation data in vector format as individual points, lets create linestring objects for each trajectory. We then load in both geopackage files (point data, and trajectory linestrings) into QGIS for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating linestring objects\n",
    "linestrings = [\n",
    "    # trajectory_idx, linestring\n",
    "]\n",
    "for trajectory_idx, trajectory_gdf in gdf_parcels.groupby(\"trajectory\"):\n",
    "    trajectory_gdf = trajectory_gdf.sort_values(\"obs\")\n",
    "    points = trajectory_gdf[\"geometry\"]\n",
    "    if points.shape[0] == 1:\n",
    "        continue  # Can't create LineString with one point\n",
    "    linestring = LineString()\n",
    "    linestrings.append((trajectory_idx, linestring))\n",
    "\n",
    "gdf_parcels_linestring = gpd.GeoDataFrame(\n",
    "    linestrings, columns=[\"trajectory\", \"geometry\"]\n",
    ")\n",
    "\n",
    "# Save linestrings to geospatial dataset using the same commands as before\n",
    "# E.g. geopackage\n",
    "gdf_parcels_linestring.to_file(\n",
    "    DATA_OUTPUT_FOLDER / f\"{DATA_OUTPUT_NAME}_linestring.gpkg\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](images/tutorial_geospatial_qgis.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas is extremely versatile as a tool to explore and analyze geospatial data. The usefulness of geopandas when it comes to analysing parcels output is further explored in the example at the end of this tutorial.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Earth\n",
    "Here we convert the trajectories to KML using `gx:Track` objects (which can have time encoded in the trajectory). We use `lxml`, a general purpose XML data editor. `fastkml` is a good option for creating KML files, but in this case doesn't explicitly support `gx` objects in its API. KMZ is just a compressed version of KML, and is not covered here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcels_geopandas_to_kml(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    path,\n",
    "    document_name=\"Parcels Particle Trajectories\",\n",
    "    rubber_ducks=True,\n",
    "):\n",
    "    \"\"\"Writes parcels trajectories to KML file.\n",
    "\n",
    "    Converts the GeoDataFrame from the `parcels_to_geopandas` function into KML\n",
    "    for use in Google Earth. Each particle trajectory is converted to a gx:Track item\n",
    "    to include timestamp information in the path.\n",
    "\n",
    "    Only uses the trajectory ID, time, lon, and lat variables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : gpd.GeoDataFrame\n",
    "        GeoDataFrame as output from the `parcels_to_geopandas` function\n",
    "\n",
    "    path : pathlike\n",
    "        Path to save the KML to.\n",
    "\n",
    "    rubber_ducks : bool\n",
    "        Replace default particle marker with rubber duck icon.\n",
    "\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    More on gx:Track in KML:\n",
    "    https://developers.google.com/kml/documentation/kmlreference#gx:track\n",
    "    \"\"\"\n",
    "    # Define namspaces\n",
    "    kml_ns = \"http://www.opengis.net/kml/2.2\"\n",
    "    gx_ns = \"http://www.google.com/kml/ext/2.2\"\n",
    "\n",
    "    kml_out = etree.Element(\"{%s}kml\" % kml_ns, nsmap={None: kml_ns, \"gx\": gx_ns})\n",
    "    document = etree.SubElement(\n",
    "        kml_out, \"Document\", id=\"1\", name=\"Particle trajectories\"\n",
    "    )\n",
    "\n",
    "    # Custom icon styling\n",
    "    if rubber_ducks:\n",
    "        icon_styling = etree.fromstring(\n",
    "            f\"\"\"<Style id=\"iconStyle\">\n",
    "                  <IconStyle>\n",
    "                    <scale>0.8</scale>\n",
    "                    <Icon>\n",
    "                      <href>https://icons.iconarchive.com/icons/thesquid.ink/free-flat-sample/256/rubber-duck-icon.png</href>\n",
    "                    </Icon>\n",
    "                  </IconStyle>\n",
    "                </Style>\n",
    "            \"\"\"\n",
    "        )\n",
    "        document.append(icon_styling)\n",
    "\n",
    "    # Generating gx:Track items\n",
    "    for trajectory_idx, trajectory_gdf in gdf.groupby(\"trajectory\"):\n",
    "        trajectory_gdf = trajectory_gdf.sort_values(\"obs\")\n",
    "\n",
    "        placemark = etree.SubElement(document, \"Placemark\")\n",
    "        name_element = etree.SubElement(placemark, \"name\")\n",
    "        name_element.text = str(trajectory_idx)\n",
    "\n",
    "        # Link custom icon styling\n",
    "        if rubber_ducks:\n",
    "            style_url = etree.SubElement(placemark, \"styleUrl\")\n",
    "            style_url.text = \"#iconStyle\"\n",
    "\n",
    "        gx_track = etree.SubElement(placemark, \"{%s}Track\" % gx_ns)\n",
    "        etree.SubElement(gx_track, \"{%s}altitudeMode\" % gx_ns, text=\"clampToGround\")\n",
    "\n",
    "        for time in trajectory_gdf[\"time\"]:\n",
    "            when_element = etree.SubElement(gx_track, \"when\")\n",
    "            when_element.text = time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        for _, row in trajectory_gdf.iterrows():\n",
    "            gx_coord_element = etree.SubElement(gx_track, \"{%s}coord\" % gx_ns)\n",
    "            gx_coord_element.text = f\"{row['geometry'].x} {row['geometry'].y} 0\"\n",
    "\n",
    "    # Save the KML to a file\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(etree.tostring(kml_out, pretty_print=True))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_geopandas_to_kml(gdf_parcels, DATA_OUTPUT_FOLDER / f\"{DATA_OUTPUT_NAME}.kml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening this kml file in Google Earth, we can explore the particle trajectories interactively:\n",
    "![Rubber ducks in the ocean](images/tutorial_geospatial_google_earth.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Kepler.gl\n",
    "> [Kepler.gl](https://kepler.gl/) is a data-agnostic, high-performance web-based application for visual exploration of large-scale geolocation data sets. Built on top of Mapbox GL and deck.gl, kepler.gl can render millions of points representing thousands of trips and perform spatial aggregations on the fly  \n",
    "> - [Kepler Docs](https://docs.kepler.gl/)\n",
    "\n",
    "For smaller visualizations, using the Kepler demo web interface is enough. To animate trips/trajectories in the web interface some customisation to the geojson file is required.\n",
    "\n",
    "> In order to animate the path, the geoJSON data needs to contain `LineString` in its feature geometry, and the coordinates in the LineString need to have 4 elements in the formats of `[longitude, latitude, altitude, timestamp]` with the last element being a timestamp. Valid timestamp formats include unix in seconds such as `1564184363` or in milliseconds such as `1564184363000`.\n",
    "> - Kepler.gl tooltip\n",
    "\n",
    "\n",
    "To do this, we can't use the same approach as before (as LineString from shapely takes a maximum of 3 values). We instead create the geojson manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_geojson(properties, coordinates):\n",
    "    \"\"\"Helper function for creating Kepler geojson\"\"\"\n",
    "    return {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {**properties},\n",
    "        \"geometry\": {\"type\": \"LineString\", \"coordinates\": coordinates},\n",
    "    }\n",
    "\n",
    "\n",
    "def create_kepler_geojson(gdf, path):\n",
    "    \"\"\"\n",
    "    Converts the GeoDataFrame from the `parcels_to_geopandas` function into geojson\n",
    "    compatible with the Kepler online viewer, and writes it to a path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf : gpd.GeoDataFrame\n",
    "        GeoDataFrame as output from the `parcels_to_geopandas` function\n",
    "\n",
    "    path : pathlike\n",
    "        Path to save the Kepler geojson to.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for trajectory_idx, trajectory_gdf in gdf.groupby(\"trajectory\"):\n",
    "        trajectory_gdf = trajectory_gdf.sort_values(\"obs\")\n",
    "\n",
    "        # Extracting point coordinates\n",
    "        trajectory_gdf[\"epoch\"] = (\n",
    "            trajectory_gdf[\"time\"] - datetime.datetime(1970, 1, 1)\n",
    "        ).dt.total_seconds()\n",
    "        coordinates = [\n",
    "            [float(row[\"geometry\"].x), float(row[\"geometry\"].y), 0, int(row[\"epoch\"])]\n",
    "            for _, row in trajectory_gdf.iterrows()\n",
    "        ]\n",
    "\n",
    "        feature_geojson = create_feature_geojson(\n",
    "            {\"pid\": int(trajectory_gdf.iloc[0][\"trajectory\"])}, coordinates\n",
    "        )\n",
    "        features.append(feature_geojson)\n",
    "\n",
    "    kepler_geojson = {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(kepler_geojson, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_kepler_geojson(\n",
    "    gdf_parcels, DATA_OUTPUT_FOLDER / f\"{DATA_OUTPUT_NAME}_kepler.geojson\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load this into the Kepler.gl website. The format of the geojson will be recognised as \"Path\" for the layer. To get good visuals, its important to tweak the display:\n",
    "\n",
    "* Trail length (measured in seconds)\n",
    "* Trail width\n",
    "* Color (can also color by attribute in the data. E.g. color by particle ID)\n",
    "\n",
    "For this simulation, a trail length of 2 day (172800 seconds) provides good visuals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Particle trajectories in Kepler](images/tutorial_geospatial_kepler.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize our trajectories in Kepler!!\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Filtering particles by starting location\n",
    "Now that we have our parcels data in a geodataframe, we can perform spatial operations with the trajectory output and other datasets. This enables deeper geospatial analysis of particle trajectories, examples including:\n",
    "\n",
    "* Finding particles that start in geographic regions\n",
    "* Finding particles that end in geographic regions\n",
    "* Finding particles that enter within `x` km of a coastline.\n",
    "\n",
    "In this worked example, we simply want to find out which of the particles start on land so we can exclude them from the analysis.\n",
    "\n",
    "The steps we follow are:\n",
    "\n",
    "* Step 1: Obtain our geospatial dataset we want to compare against\n",
    "    * Here we use [ESRI's World Countries Dataset](https://hub.arcgis.com/datasets/esri::world-countries-generalized) in geojson format to get polygons of the countries. Alternatively you can create your own polygons in GIS software and export as geojson/shapefile/geopackage for use in Python.\n",
    "* Step 2: Filter observations to get first observation only for each particle\n",
    "* Step 3: Spatial join our data\n",
    "* Step 4: Filter observations to get only the particles in the water\n",
    "* Step 5: Use particle IDs to subset the original xarray dataset, which can be further analyzed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Obtain our geospatial datasets we want to compare against\n",
    "esri_dataset_url = \"https://services.arcgis.com/P3ePLMYs2RVChkJx/arcgis/rest/services/World_Countries_(Generalized)/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson\"\n",
    "\n",
    "response = requests.get(esri_dataset_url)\n",
    "if response.status_code == 200:\n",
    "    geojson_data = response.json()\n",
    "else:\n",
    "    raise Exception(\n",
    "        f\"Failed data request for {esri_dataset_url}. Status code {response.status_code}\"\n",
    "    )\n",
    "\n",
    "gdf_countries = gpd.GeoDataFrame.from_features(geojson_data[\"features\"]).set_crs(\n",
    "    \"EPSG:4326\"\n",
    ")\n",
    "gdf_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter observations to get first observation only for each particle\n",
    "gdf_parcels_initial = gdf_parcels.drop_duplicates(subset=\"trajectory\", keep=\"first\")\n",
    "\n",
    "# Step 3: Spatial join our data\n",
    "gdf_parcels_initial = gdf_parcels_initial.sjoin(\n",
    "    gdf_countries[[\"geometry\", \"COUNTRY\"]], how=\"left\", predicate=\"intersects\"\n",
    ")\n",
    "gdf_parcels_initial.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Filter observations to get only the particles in the water\n",
    "water_particles_mask = gdf_parcels_initial[\"COUNTRY\"].isna()\n",
    "\n",
    "particles_in_water = gdf_parcels_initial[water_particles_mask][\"trajectory\"].values\n",
    "particles_on_land = gdf_parcels_initial[~water_particles_mask][\"trajectory\"].values\n",
    "\n",
    "print(\n",
    "    f\"Particles with the following trajectory IDs are start in water:\\n{particles_in_water}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"Particles with the following trajectory IDs are start on land:\\n{particles_on_land}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These land particles match the particles on land in the Google Earth visualization from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Use particle IDs to subset the original xarray dataset, which can be further analyzed.\n",
    "ds_parcels_in_water = ds_parcels.sel(trajectory=particles_in_water)\n",
    "\n",
    "# Continue analysis..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "That's it! You can now integrate Parcels with a variety of geospatial applications.\n",
    "\n",
    "If there is any additional info, corrections, or geospatial tooling you feel this tutorial can benefit from mentioning, please submit an issue or pull request in the [OceanParcels GitHub](https://github.com/oceanparcels/parcels)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
