{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeStamps and calendars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from parcels import Field, download_example_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some NetCDF files, such as for example those from the [World Ocean Atlas](https://www.nodc.noaa.gov/OC5/woa18/), have time calendars that can't be parsed by `xarray`. These result in a `ValueError: unable to decode time units`, for example when the calendar is in 'months since' a particular date.\n",
    "\n",
    "In these cases, a workaround in Parcels is to use the `timestamps` argument in `Field` (or `FieldSet`) creation. Here, we show how this works for example temperature data from the World Ocean Atlas in the Pacific Ocean\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell raises an error, since the calendar of the World Ocean Atlas data is in \"months since 1955-01-01 00:00:00\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: File /Users/erik/Library/Caches/parcels/WOA_data/woa18_decav_t10_04.nc could not be decoded properly by xarray (version 2023.9.0). It will be opened with no decoding. Filling values might be wrongly parsed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Xarray could not convert the calendar. If youre using from_netcdf, try using the timestamps keyword in the construction of your Field. See also the tutorial at https://docs.oceanparcels.org/en/latest/examples/tutorial_timestamps.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/coding/times.py:319\u001b[0m, in \u001b[0;36mdecode_cf_datetime\u001b[0;34m(num_dates, units, calendar, use_cftime)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     dates \u001b[39m=\u001b[39m _decode_datetime_with_pandas(flat_num_dates, units, calendar)\n\u001b[1;32m    320\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyError\u001b[39;00m, OutOfBoundsDatetime, OutOfBoundsTimedelta, \u001b[39mOverflowError\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/coding/times.py:253\u001b[0m, in \u001b[0;36m_decode_datetime_with_pandas\u001b[0;34m(flat_num_dates, units, calendar)\u001b[0m\n\u001b[1;32m    252\u001b[0m time_units, ref_date \u001b[39m=\u001b[39m _unpack_netcdf_time_units(units)\n\u001b[0;32m--> 253\u001b[0m time_units \u001b[39m=\u001b[39m _netcdf_to_numpy_timeunit(time_units)\n\u001b[1;32m    254\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[39m# TODO: the strict enforcement of nanosecond precision Timestamps can be\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39m# relaxed when addressing GitHub issue #7493.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/coding/times.py:115\u001b[0m, in \u001b[0;36m_netcdf_to_numpy_timeunit\u001b[0;34m(units)\u001b[0m\n\u001b[1;32m    114\u001b[0m     units \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00munits\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mnanoseconds\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mns\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    117\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mmicroseconds\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mus\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    118\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mmilliseconds\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mms\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    119\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mseconds\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39ms\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    120\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mminutes\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    121\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mhours\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mh\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    122\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mdays\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mD\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    123\u001b[0m }[units]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'months'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/coding/times.py:213\u001b[0m, in \u001b[0;36m_decode_cf_datetime_dtype\u001b[0;34m(data, units, calendar, use_cftime)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     result \u001b[39m=\u001b[39m decode_cf_datetime(example_value, units, calendar, use_cftime)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/coding/times.py:321\u001b[0m, in \u001b[0;36mdecode_cf_datetime\u001b[0;34m(num_dates, units, calendar, use_cftime)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyError\u001b[39;00m, OutOfBoundsDatetime, OutOfBoundsTimedelta, \u001b[39mOverflowError\u001b[39;00m):\n\u001b[0;32m--> 321\u001b[0m     dates \u001b[39m=\u001b[39m _decode_datetime_with_cftime(\n\u001b[1;32m    322\u001b[0m         flat_num_dates\u001b[39m.\u001b[39;49mastype(\u001b[39mfloat\u001b[39;49m), units, calendar\n\u001b[1;32m    323\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    326\u001b[0m         dates[np\u001b[39m.\u001b[39mnanargmin(num_dates)]\u001b[39m.\u001b[39myear \u001b[39m<\u001b[39m \u001b[39m1678\u001b[39m\n\u001b[1;32m    327\u001b[0m         \u001b[39mor\u001b[39;00m dates[np\u001b[39m.\u001b[39mnanargmax(num_dates)]\u001b[39m.\u001b[39myear \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2262\u001b[39m\n\u001b[1;32m    328\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/coding/times.py:237\u001b[0m, in \u001b[0;36m_decode_datetime_with_cftime\u001b[0;34m(num_dates, units, calendar)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mif\u001b[39;00m num_dates\u001b[39m.\u001b[39msize \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    236\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m--> 237\u001b[0m         cftime\u001b[39m.\u001b[39;49mnum2date(num_dates, units, calendar, only_use_cftime_datetimes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32msrc/cftime/_cftime.pyx:580\u001b[0m, in \u001b[0;36mcftime._cftime.num2date\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/cftime/_cftime.pyx:98\u001b[0m, in \u001b[0;36mcftime._cftime._dateparse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'months since' units only allowed for '360_day' calendar",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/conventions.py:428\u001b[0m, in \u001b[0;36mdecode_cf_variables\u001b[0;34m(variables, attributes, concat_characters, mask_and_scale, decode_times, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 428\u001b[0m     new_vars[k] \u001b[39m=\u001b[39m decode_cf_variable(\n\u001b[1;32m    429\u001b[0m         k,\n\u001b[1;32m    430\u001b[0m         v,\n\u001b[1;32m    431\u001b[0m         concat_characters\u001b[39m=\u001b[39;49mconcat_characters,\n\u001b[1;32m    432\u001b[0m         mask_and_scale\u001b[39m=\u001b[39;49mmask_and_scale,\n\u001b[1;32m    433\u001b[0m         decode_times\u001b[39m=\u001b[39;49mdecode_times,\n\u001b[1;32m    434\u001b[0m         stack_char_dim\u001b[39m=\u001b[39;49mstack_char_dim,\n\u001b[1;32m    435\u001b[0m         use_cftime\u001b[39m=\u001b[39;49muse_cftime,\n\u001b[1;32m    436\u001b[0m         decode_timedelta\u001b[39m=\u001b[39;49mdecode_timedelta,\n\u001b[1;32m    437\u001b[0m     )\n\u001b[1;32m    438\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/conventions.py:279\u001b[0m, in \u001b[0;36mdecode_cf_variable\u001b[0;34m(name, var, concat_characters, mask_and_scale, decode_times, decode_endianness, stack_char_dim, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m decode_times:\n\u001b[0;32m--> 279\u001b[0m     var \u001b[39m=\u001b[39m times\u001b[39m.\u001b[39;49mCFDatetimeCoder(use_cftime\u001b[39m=\u001b[39;49muse_cftime)\u001b[39m.\u001b[39;49mdecode(var, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m decode_endianness \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m var\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39misnative:\n",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/coding/times.py:831\u001b[0m, in \u001b[0;36mCFDatetimeCoder.decode\u001b[0;34m(self, variable, name)\u001b[0m\n\u001b[1;32m    830\u001b[0m calendar \u001b[39m=\u001b[39m pop_to(attrs, encoding, \u001b[39m\"\u001b[39m\u001b[39mcalendar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 831\u001b[0m dtype \u001b[39m=\u001b[39m _decode_cf_datetime_dtype(data, units, calendar, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_cftime)\n\u001b[1;32m    832\u001b[0m transform \u001b[39m=\u001b[39m partial(\n\u001b[1;32m    833\u001b[0m     decode_cf_datetime,\n\u001b[1;32m    834\u001b[0m     units\u001b[39m=\u001b[39munits,\n\u001b[1;32m    835\u001b[0m     calendar\u001b[39m=\u001b[39mcalendar,\n\u001b[1;32m    836\u001b[0m     use_cftime\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_cftime,\n\u001b[1;32m    837\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/coding/times.py:223\u001b[0m, in \u001b[0;36m_decode_cf_datetime_dtype\u001b[0;34m(data, units, calendar, use_cftime)\u001b[0m\n\u001b[1;32m    218\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munable to decode time units \u001b[39m\u001b[39m{\u001b[39;00munits\u001b[39m!r}\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m{\u001b[39;00mcalendar_msg\u001b[39m!r}\u001b[39;00m\u001b[39m. Try \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mopening your dataset with decode_times=False or installing cftime \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mif it is not installed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: unable to decode time units 'months since 1955-01-01 00:00:00' with 'the default calendar'. Try opening your dataset with decode_times=False or installing cftime if it is not installed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Codes/ParcelsCode/parcels/tools/converters.py:266\u001b[0m, in \u001b[0;36mconvert_xarray_time_units\u001b[0;34m(ds, time)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     da2 \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39;49mdecode_cf(da2)\n\u001b[1;32m    267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/conventions.py:569\u001b[0m, in \u001b[0;36mdecode_cf\u001b[0;34m(obj, concat_characters, mask_and_scale, decode_times, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcan only decode Dataset or DataStore objects\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 569\u001b[0m \u001b[39mvars\u001b[39m, attrs, coord_names \u001b[39m=\u001b[39m decode_cf_variables(\n\u001b[1;32m    570\u001b[0m     \u001b[39mvars\u001b[39;49m,\n\u001b[1;32m    571\u001b[0m     attrs,\n\u001b[1;32m    572\u001b[0m     concat_characters,\n\u001b[1;32m    573\u001b[0m     mask_and_scale,\n\u001b[1;32m    574\u001b[0m     decode_times,\n\u001b[1;32m    575\u001b[0m     decode_coords,\n\u001b[1;32m    576\u001b[0m     drop_variables\u001b[39m=\u001b[39;49mdrop_variables,\n\u001b[1;32m    577\u001b[0m     use_cftime\u001b[39m=\u001b[39;49muse_cftime,\n\u001b[1;32m    578\u001b[0m     decode_timedelta\u001b[39m=\u001b[39;49mdecode_timedelta,\n\u001b[1;32m    579\u001b[0m )\n\u001b[1;32m    580\u001b[0m ds \u001b[39m=\u001b[39m Dataset(\u001b[39mvars\u001b[39m, attrs\u001b[39m=\u001b[39mattrs)\n",
      "File \u001b[0;32m~/miniconda3/envs/parcels/lib/python3.11/site-packages/xarray/conventions.py:439\u001b[0m, in \u001b[0;36mdecode_cf_variables\u001b[0;34m(variables, attributes, concat_characters, mask_and_scale, decode_times, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to decode variable \u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m decode_coords \u001b[39min\u001b[39;00m [\u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mcoordinates\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to decode variable 'time': unable to decode time units 'months since 1955-01-01 00:00:00' with 'the default calendar'. Try opening your dataset with decode_times=False or installing cftime if it is not installed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/erik/Codes/ParcelsCode/docs/examples/tutorial_timestamps.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/erik/Codes/ParcelsCode/docs/examples/tutorial_timestamps.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m example_dataset_folder \u001b[39m=\u001b[39m download_example_dataset(\u001b[39m\"\u001b[39m\u001b[39mWOA_data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/erik/Codes/ParcelsCode/docs/examples/tutorial_timestamps.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tempfield \u001b[39m=\u001b[39m Field\u001b[39m.\u001b[39;49mfrom_netcdf(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/erik/Codes/ParcelsCode/docs/examples/tutorial_timestamps.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     glob(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mexample_dataset_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/woa18_decav_*_04.nc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/erik/Codes/ParcelsCode/docs/examples/tutorial_timestamps.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mt_an\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/erik/Codes/ParcelsCode/docs/examples/tutorial_timestamps.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mlon\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mlon\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlat\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mlat\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/erik/Codes/ParcelsCode/docs/examples/tutorial_timestamps.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Codes/ParcelsCode/parcels/field.py:457\u001b[0m, in \u001b[0;36mField.from_netcdf\u001b[0;34m(cls, filenames, variable, dimensions, indices, grid, mesh, timestamps, allow_time_extrapolation, time_periodic, deferred_load, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mMultiple files given but no time dimension specified\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    454\u001b[0m \u001b[39mif\u001b[39;00m grid \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     \u001b[39m# Concatenate time variable to determine overall dimension\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[39m# across multiple files\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     time, time_origin, timeslices, dataFiles \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_timeslices(timestamps, data_filenames,\n\u001b[1;32m    458\u001b[0m                                                                       _grid_fb_class, dimensions,\n\u001b[1;32m    459\u001b[0m                                                                       indices, netcdf_engine, netcdf_decodewarning)\n\u001b[1;32m    460\u001b[0m     grid \u001b[39m=\u001b[39m Grid\u001b[39m.\u001b[39mcreate_grid(lon, lat, depth, time, time_origin\u001b[39m=\u001b[39mtime_origin, mesh\u001b[39m=\u001b[39mmesh)\n\u001b[1;32m    461\u001b[0m     grid\u001b[39m.\u001b[39mtimeslices \u001b[39m=\u001b[39m timeslices\n",
      "File \u001b[0;32m~/Codes/ParcelsCode/parcels/field.py:290\u001b[0m, in \u001b[0;36mField.collect_timeslices\u001b[0;34m(timestamps, data_filenames, _grid_fb_class, dimensions, indices, netcdf_engine, netcdf_decodewarning)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m data_filenames:\n\u001b[1;32m    288\u001b[0m     \u001b[39mwith\u001b[39;00m _grid_fb_class(fname, dimensions, indices, netcdf_engine\u001b[39m=\u001b[39mnetcdf_engine,\n\u001b[1;32m    289\u001b[0m                         netcdf_decodewarning\u001b[39m=\u001b[39mnetcdf_decodewarning) \u001b[39mas\u001b[39;00m filebuffer:\n\u001b[0;32m--> 290\u001b[0m         ftime \u001b[39m=\u001b[39m filebuffer\u001b[39m.\u001b[39;49mtime\n\u001b[1;32m    291\u001b[0m         timeslices\u001b[39m.\u001b[39mappend(ftime)\n\u001b[1;32m    292\u001b[0m         dataFiles\u001b[39m.\u001b[39mappend([fname] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(ftime))\n",
      "File \u001b[0;32m~/Codes/ParcelsCode/parcels/fieldfilebuffer.py:215\u001b[0m, in \u001b[0;36mNetcdfFileBuffer.time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtime\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtime_access()\n",
      "File \u001b[0;32m~/Codes/ParcelsCode/parcels/fieldfilebuffer.py:225\u001b[0m, in \u001b[0;36mNetcdfFileBuffer.time_access\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([\u001b[39mNone\u001b[39;00m])\n\u001b[1;32m    224\u001b[0m time_da \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimensions[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m--> 225\u001b[0m convert_xarray_time_units(time_da, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdimensions[\u001b[39m'\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    226\u001b[0m time \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([time_da[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimensions[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mdata]) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(time_da\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39marray(time_da[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimensions[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(time[\u001b[39m0\u001b[39m], datetime\u001b[39m.\u001b[39mdatetime):\n",
      "File \u001b[0;32m~/Codes/ParcelsCode/parcels/tools/converters.py:268\u001b[0m, in \u001b[0;36mconvert_xarray_time_units\u001b[0;34m(ds, time)\u001b[0m\n\u001b[1;32m    266\u001b[0m     da2 \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mdecode_cf(da2)\n\u001b[1;32m    267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mXarray could not convert the calendar. If you\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre using from_netcdf, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    269\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mtry using the timestamps keyword in the construction of your Field. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    270\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mSee also the tutorial at https://docs.oceanparcels.org/en/latest/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    271\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mexamples/tutorial_timestamps.html\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    272\u001b[0m ds[time] \u001b[39m=\u001b[39m da2[time]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Xarray could not convert the calendar. If youre using from_netcdf, try using the timestamps keyword in the construction of your Field. See also the tutorial at https://docs.oceanparcels.org/en/latest/examples/tutorial_timestamps.html"
     ]
    }
   ],
   "source": [
    "example_dataset_folder = download_example_dataset(\"WOA_data\")\n",
    "tempfield = Field.from_netcdf(\n",
    "    glob(f\"{example_dataset_folder}/woa18_decav_*_04.nc\"),\n",
    "    \"t_an\",\n",
    "    {\"lon\": \"lon\", \"lat\": \"lat\", \"time\": \"time\"},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can create our own numpy array of timestamps associated with each of the 12 snapshots in the netcdf file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.expand_dims(\n",
    "    np.array([np.datetime64(\"2001-%.2d-15\" % m) for m in range(1, 13)]), axis=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can add the `timestamps` as an extra argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempfield = Field.from_netcdf(\n",
    "    glob(f\"{example_dataset_folder}/woa18_decav_*_04.nc\"),\n",
    "    \"t_an\",\n",
    "    {\"lon\": \"lon\", \"lat\": \"lat\", \"time\": \"time\"},\n",
    "    netcdf_decodewarning=False,\n",
    "    timestamps=timestamps,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, by the way, that adding the `time_periodic` argument to `Field.from_netcdf()` will also mean that the climatology can be cycled for multiple years.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, note that we used `netcdf_decodewarning=False` in the `FieldSet.from_netcdf()` call above. This is to silence an expected warning because the time dimension in the `coordinates.nc` file can't be decoded by `xarray`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
