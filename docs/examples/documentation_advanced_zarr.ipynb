{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 0.058812,
     "end_time": "2023-02-05T12:56:42.979406",
     "exception": false,
     "start_time": "2023-02-05T12:56:42.920594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Output in zarr (advanced)\n",
    "\n",
    "Topics:\n",
    "\n",
    "- Capturing output in memory using the `MemoryStore` of `zarr` ([link](https://zarr.readthedocs.io/en/v2.18.5/api/storage.html#zarr.storage.MemoryStore))\n",
    "- Transferring data from a `MemoryStore` into a directory (via `DirectoryStore`; [link](https://zarr.readthedocs.io/en/v2.18.5/api/storage.html#zarr.storage.DirectoryStore)) or a zip file (via `ZipStore`; [link](https://zarr.readthedocs.io/en/v2.18.5/api/storage.html#zarr.storage.ZipStore)).\n",
    "- Re-chunking output to better align with specific analyses (time vs. spatial filtering).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## A simple flow field\n",
    "\n",
    "We'll use a Rankine Vortex (https://en.wikipedia.org/wiki/Rankine_vortex) and add some noise to make trajectories interesting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)  # let's be reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = xr.DataArray(np.linspace(-20, 20, 101), dims=(\"lat\",), name=\"lat\")\n",
    "lon = xr.DataArray(np.linspace(-20, 20, 101), dims=(\"lon\",), name=\"lon\")\n",
    "\n",
    "# rankine vortex:\n",
    "Vmax = 1.5\n",
    "Vnoise = 0.2\n",
    "phi = np.arctan2(lat, lon)\n",
    "r = (lat**2 + lon**2) ** 0.5\n",
    "core_rad = 10\n",
    "rad_structure = xr.where(r <= core_rad, r / core_rad, core_rad / r)\n",
    "U_noise = np.random.normal(0, Vnoise, size=r.shape)\n",
    "V_noise = np.random.normal(0, Vnoise, size=r.shape)\n",
    "\n",
    "# the dataset\n",
    "ds_flow_field = xr.Dataset(\n",
    "    {\n",
    "        \"U\": (Vmax * -np.sin(phi) * rad_structure + U_noise).rename(\"U\"),\n",
    "        \"V\": (Vmax * np.cos(phi) * rad_structure + V_noise).rename(\"V\"),\n",
    "    },\n",
    "    coords={\"lat\": lat, \"lon\": lon},\n",
    ")\n",
    "\n",
    "display(ds_flow_field)\n",
    "\n",
    "((ds_flow_field.U**2 + ds_flow_field.V**2) ** 0.5).plot()\n",
    "\n",
    "(\n",
    "    ds_flow_field.isel(lon=slice(None, None, 3), lat=slice(None, None, 3)).plot.quiver(\n",
    "        x=\"lon\", y=\"lat\", u=\"U\", v=\"V\"\n",
    "    )\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": 0.015861,
     "end_time": "2023-02-05T12:56:46.746560",
     "exception": false,
     "start_time": "2023-02-05T12:56:46.730699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Parcels experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": 0.153963,
     "end_time": "2023-02-05T12:56:46.916662",
     "exception": false,
     "start_time": "2023-02-05T12:56:46.762699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "import parcels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Create fieldset from Xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldset = parcels.FieldSet.from_xarray_dataset(\n",
    "    ds_flow_field,\n",
    "    variables={\"U\": \"U\", \"V\": \"V\"},\n",
    "    dimensions={\"lat\": \"lat\", \"lon\": \"lon\"},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": 0.017419,
     "end_time": "2023-02-05T12:56:47.032698",
     "exception": false,
     "start_time": "2023-02-05T12:56:47.015279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### A randomly positioned particleset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "papermill": {
     "duration": 0.031583,
     "end_time": "2023-02-05T12:56:47.080957",
     "exception": false,
     "start_time": "2023-02-05T12:56:47.049374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_random_pset(\n",
    "    fieldset=None, lon_range=(-15, 15), lat_range=(-15, 15), number_particles=200\n",
    "):\n",
    "    return parcels.ParticleSet.from_list(\n",
    "        fieldset=fieldset,\n",
    "        pclass=parcels.Particle,\n",
    "        lon=np.random.uniform(*lon_range, size=(number_particles,)),\n",
    "        lat=np.random.uniform(*lat_range, size=(number_particles,)),\n",
    "        time=np.zeros(shape=(number_particles,)),\n",
    "    )\n",
    "\n",
    "\n",
    "pset = create_random_pset(fieldset)\n",
    "\n",
    "plt.plot(pset.lon, pset.lat, \"o\", alpha=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "papermill": {
     "duration": 0.019595,
     "end_time": "2023-02-05T12:56:47.116811",
     "exception": false,
     "start_time": "2023-02-05T12:56:47.097216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Streaming to an _in-memory_ store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fresh particle set\n",
    "pset = create_random_pset(fieldset)\n",
    "\n",
    "# create output store and output file\n",
    "output_memorystore = zarr.storage.MemoryStore()\n",
    "outputfile = pset.ParticleFile(name=output_memorystore, outputdt=timedelta(hours=3))\n",
    "\n",
    "# run experiment\n",
    "pset.execute(\n",
    "    parcels.AdvectionRK4,\n",
    "    runtime=timedelta(days=17),\n",
    "    dt=timedelta(hours=3),\n",
    "    output_file=outputfile,\n",
    ")\n",
    "\n",
    "# load output\n",
    "ds_out = xr.open_zarr(output_memorystore)\n",
    "display(ds_out)\n",
    "\n",
    "# have a look\n",
    "ds_out.to_dataframe().plot.scatter(x=\"lon\", y=\"lat\", s=2, alpha=0.1);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Saving to an other Zarr store\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Directory, without changing chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create store\n",
    "output_dirstore_name = \"zarr_advanced_01.zarr/\"\n",
    "!rm -rf {output_dirstore_name}\n",
    "output_dirstore = zarr.storage.DirectoryStore(output_dirstore_name)\n",
    "\n",
    "# copy\n",
    "zarr.convenience.copy_store(output_memorystore, output_dirstore)\n",
    "output_dirstore.close()\n",
    "\n",
    "# have a quick look\n",
    "ds_out = xr.open_zarr(output_dirstore_name)\n",
    "display(ds_out)\n",
    "ds_out.to_dataframe().plot.scatter(x=\"lon\", y=\"lat\", s=2, alpha=0.1);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Zipfile, without changing chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create store\n",
    "output_zipstore_name = \"zarr_advanced_01.zip\"\n",
    "!rm -f {output_zipstore_name}\n",
    "output_zipstore = zarr.storage.ZipStore(output_zipstore_name, mode=\"w\")\n",
    "\n",
    "# copy\n",
    "zarr.convenience.copy_store(output_memorystore, output_zipstore)\n",
    "output_zipstore.close()\n",
    "\n",
    "# have a quick look\n",
    "ds_out = xr.open_zarr(output_zipstore_name)\n",
    "display(ds_out)\n",
    "ds_out.to_dataframe().plot.scatter(x=\"lon\", y=\"lat\", s=2, alpha=0.1);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Rechunking and saving to new stores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Consider the current chunking (let's load the memory store again):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out_orig = xr.open_zarr(output_memorystore)\n",
    "display(ds_out_orig.lat.data)\n",
    "display(ds_out_orig.chunks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "So we have one chunk per `obs` slice which covers all trajectories. This is the optimal way of _creating_ the recorded dataset at simulation time, but may not be ideal for, e.g., time filtering.\n",
    "\n",
    "So let's turn this into a store which only covers 10 trajectories per chunk but 40 time steps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out_rechunked = ds_out_orig.chunk({\"trajectory\": 10, \"obs\": 40})\n",
    "display(ds_out_rechunked.lat.data)\n",
    "display(ds_out_rechunked.chunks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "And of course, we could now save the rechunked data into a zip store or a directory store:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary because of https://github.com/pydata/xarray/issues/4380\n",
    "for vname, vobj in ds_out_rechunked.data_vars.items():\n",
    "    if \"chunks\" in vobj.encoding:\n",
    "        del vobj.encoding[\"chunks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out_rechunked.to_zarr(\"zarr_advanced_01_rechunked.zarr/\", mode=\"w\")\n",
    "# new directory store\n",
    "ds_out_rechunked.to_zarr(\n",
    "    zarr.storage.ZipStore(\"zarr_advanced_01_rechunked.zip\", mode=\"w\")\n",
    ");  # new zip store"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.423996,
   "end_time": "2023-02-05T12:56:54.785370",
   "environment_variables": {},
   "exception": null,
   "input_path": "2023-02-03_first_steps.ipynb",
   "output_path": "2023-02-03_first_steps.exe.ipynb",
   "parameters": {},
   "start_time": "2023-02-05T12:56:41.361374",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
